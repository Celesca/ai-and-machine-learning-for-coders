{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"In the town of Athy one Jeremy Lanigan\n",
    "Battered away 'til he hadn't a pound.\n",
    "His father he died and made him a man again\n",
    "Left him a farm and ten acres of ground.\n",
    "He gave a grand party to friends and relations\n",
    "Who didn't forget him when it comes to the will,\n",
    "If you'll but listen I'll make your eyes glisten\n",
    "Of the rows and the ructions of Lanigan's Ball.\n",
    "Six long months I spent in Dublin,\n",
    "Six long months doing nothing at all.\n",
    "Six long months I spent in Dublin,\n",
    "Learning to dance for Lanigan's ball.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the town of Athy one Jeremy Lanigan\n",
      "Battered away 'til he hadn't a pound.\n",
      "His father he died and made him a man again\n",
      "Left him a farm and ten acres of ground.\n",
      "He gave a grand party to friends and relations\n",
      "Who didn't forget him when it comes to the will,\n",
      "If you'll but listen I'll make your eyes glisten\n",
      "Of the rows and the ructions of Lanigan's Ball.\n",
      "Six long months I spent in Dublin,\n",
      "Six long months doing nothing at all.\n",
      "Six long months I spent in Dublin,\n",
      "Learning to dance for Lanigan's ball.\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in the town of athy one jeremy lanigan', \"battered away 'til he hadn't a pound.\", 'his father he died and made him a man again', 'left him a farm and ten acres of ground.', 'he gave a grand party to friends and relations', \"who didn't forget him when it comes to the will,\", \"if you'll but listen i'll make your eyes glisten\", \"of the rows and the ructions of lanigan's ball.\", 'six long months i spent in dublin,', 'six long months doing nothing at all.', 'six long months i spent in dublin,', \"learning to dance for lanigan's ball.\"]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ทำให้เป็นชุดของลำดับย่อย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 1, 17, 2, 18, 19, 20, 21]\n",
      "[22, 23, 24, 6, 25, 3, 26]\n",
      "[27, 28, 6, 29, 4, 30, 7, 3, 31, 32]\n",
      "[33, 7, 3, 34, 4, 35, 36, 2, 37]\n",
      "[6, 38, 3, 39, 40, 8, 41, 4, 42]\n",
      "[43, 44, 45, 7, 46, 47, 48, 8, 1, 49]\n",
      "[50, 51, 52, 53, 54, 55, 56, 57, 58]\n",
      "[2, 1, 59, 4, 1, 60, 2, 12, 13]\n",
      "[9, 10, 11, 14, 15, 5, 16]\n",
      "[9, 10, 11, 61, 62, 63, 64]\n",
      "[9, 10, 11, 14, 15, 5, 16]\n",
      "[65, 8, 66, 67, 12, 13]\n",
      "[[5, 1], [5, 1, 17], [5, 1, 17, 2], [5, 1, 17, 2, 18], [5, 1, 17, 2, 18, 19]]\n"
     ]
    }
   ],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    print(token_list)\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "print(input_sequences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepadding ข้อมูล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input sequences and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label to be the categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ys \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(labels, num_classes\u001b[38;5;241m=\u001b[39mtotal_words)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
